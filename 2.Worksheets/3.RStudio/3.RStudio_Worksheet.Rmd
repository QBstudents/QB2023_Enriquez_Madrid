---
title: '3\. Worksheet: Basic R'
author: "Jonathan Enriquez Madrid; Z620: Quantitative Biodiversity, Indiana University"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
geometry: margin=2.54cm
---

## OVERVIEW

This worksheet introduces some of the basic features of the R computing environment (http://www.r-project.org).
It is designed to be used along side the **3. RStudio** handout in your binder. 
You will not be able to complete the exercises without the corresponding handout.

## Directions:
1. In the Markdown version of this document in your cloned repo, change "Student Name" on line 3 (above) with your name.
2. Complete as much of the worksheet as possible during class.
3. Use the handout as a guide; it contains a more complete description of data sets along with examples of proper scripting needed to carry out the exercises.
4. Answer questions in the  worksheet.
Space for your answers is provided in this document and is indicated by the ">" character.
If you need a second paragraph be sure to start the first line with ">".
You should notice that the answer is highlighted in green by RStudio (color may vary if you changed the editor theme). 
5. Before you leave the classroom today, it is *imperative* that you **push** this file to your GitHub repo, at whatever stage you are. Ths will enable you to pull your work onto your own computer.
6. When you have completed the worksheet, **Knit** the text and code into a single PDF file by pressing the `Knit` button in the RStudio scripting panel.
This will save the PDF output in your '3.RStudio' folder.
7. After Knitting, please submit the worksheet by making a **push** to your GitHub repo and then create a **pull request** via GitHub.
Your pull request should include this file (**3.RStudio_Worksheet.Rmd**) with all code blocks filled out and questions answered) and the PDF output of `Knitr` (**3.RStudio_Worksheet.pdf**).

The completed exercise is due on **Wednesday, January 18^th^, 2023 before 12:00 PM (noon)**.

## 1) HOW WE WILL BE USING R AND OTHER TOOLS

You are working in an RMarkdown (.Rmd) file.
This allows you to integrate text and R code into a single document.
There are two major features to this document: 1) Markdown formatted text and 2) "chunks" of R code.
Anything in an R code chunk will be interpreted by R when you *Knit* the document.

When you are done, you will *knit* your document together.
However, if there are errors in the R code contained in your Markdown document, you will not be able to knit a PDF file. 
If this happens, you will need to review your code, locate the source of the error(s), and make the appropriate changes.
Even if you are able to knit without issue, you should review the knitted document for correctness and completeness before you submit the Worksheet. Next to the `Knit` button in the RStudio scripting panel there is a spell checker button (`ABC`) button.

## 2) SETTING YOUR WORKING DIRECTORY

In the R code chunk below, please provide the code to: 
1) clear your R environment,
2) print your current working directory, and
3) set your working directory to your '3.RStudio' folder. 

```{r}

rm(list = ls())
getwd()
setwd("C:/Users/jonat/GitHub/QB2023_Enriquez_Madrid/2.Worksheets/3.RStudio")

```

## 3) USING R AS A CALCULATOR

To follow up on the pre-class exercises, please calculate the following in the R code chunk below. 
Feel free to reference the **1. Introduction to version control and computing tools** handout. 

1) the volume of a cube with length, l, = 5 (volume = l^3 )
2) the area of a circle with radius, r, = 2 (area = pi * r^2). 
3) the length of the opposite side of a right-triangle given that the angle, theta, = pi/4. (radians, a.k.a. 45°) and with hypotenuse length sqrt(2) (remember: sin(theta) = opposite/hypotenuse).
4) the log (base e) of your favorite number.

```{r}
5^3    #125
pi*2^2   #12.56637
sqrt(2)*sin(pi/4)     #1
log(7)    #1.94591
```

## 4) WORKING WITH VECTORS

To follow up on the pre-class exercises, please perform the requested operations in the R-code chunks below.

### Basic Features Of Vectors

In the R-code chunk below, do the following: 
1) Create a vector `x` consisting of any five numbers.
2) Create a new vector `w` by multiplying `x` by 14 (i.e., "scalar").
3) Add `x` and `w` and divide by 15.

```{r}
x<- c(1, 2, 3, 4, 5) #Vector made
w<- x*14 #Vector made
y<- x+w  #x and w added together
y/15 #1,2,3,4,5
```

Now, do the following: 
1) Create another vector (`k`) that is the same length as `w`.
2) Multiply `k` by `x`.
3) Use the combine function to create one more vector, `d` that consists of any three elements from `w` and any four elements of `k`.

```{r}
k<- c(5, 10, 15, 20, 25) #vector made
k*x #5, 20, 45, 80, 125
d<- c(14, 28, 42, 5, 10, 15, 20) #vector made
```

### Summary Statistics of Vectors

In the R-code chunk below, calculate the **summary statistics** (i.e., maximum, minimum, sum, mean, median, variance, standard deviation, and standard error of the mean) for the vector (`v`) provided.

```{r}
v <- c(16.4, 16.0, 10.1, 16.8, 20.5, NA, 20.2, 13.1, 24.8, 20.2, 25.0, 20.5, 30.5, 31.4, 27.1)
max(na.omit(v)) #31.4
min(na.omit(v)) #10.1
sum(na.omit(v)) #292.6
mean(na.omit(v)) #20.9
median(na.omit(v)) #20.35
var(na.omit(v)) #39.44
sd(na.omit(v)) #6.280127






```

## 5) WORKING WITH MATRICES

In the R-code chunk below, do the following:
Using a mixture of Approach 1 and 2 from the **3. RStudio** handout, create a matrix with two columns and five rows.
Both columns should consist of random numbers.
Make the mean of the first column equal to 8 with a standard deviation of 2 and the mean of the second column equal to 25 with a standard deviation of 10.

```{r}
j<- c(rnorm(5, mean = 8, sd = 2))
z<- c(rnorm(5, mean = 25, sd = 10))
k2<- cbind(z, j) 
k2 #Gives a matrix with two columns and five rows with the required means and standard deviations
help(rnorm)
```

***Question 1***: What does the `rnorm` function do? 
What do the arguments in this function specify? 
Remember to use `help()` or type `?rnorm`.

> Answer 1: rnorm generates a random distribution of numbers, specifying the mean and standard deviation in the vector of numbers.
>The arguments in this function sepcify vector of quantiles, vector of probabilities, number of observations, vector of means, vector of standard deviations, log, and lower.tail (P[X<\=x] as the defualt and P[X>x] for the nondefualt.


In the R code chunk below, do the following: 
1) Load `matrix.txt` from the **3.RStudio** data folder as matrix `m`.
2) Transpose this matrix.
3) Determine the dimensions of the transposed matrix.

```{r}
m <- as.matrix(read.table("data/matrix.txt", sep = "\t", header = FALSE)) 
n <- t(m) #transposed m
dim(n) #Five rows and ten columns. m has ten rows and five columns.
dim(m)
```


***Question 2***: What are the dimensions of the matrix you just transposed?

> Answer 2: The dimensions of the matrix I just transposed are 5 rows and 10 columns. 


###Indexing a Matrix

In the R code chunk below, do the following:
1) Index matrix `m` by selecting all but the third column.
2) Remove the last row of matrix `m`.

```{r}
library(dplyr)
m2 <- m[, c(1,2,4,5)]# Indexed matrix to include all columns but the third.
m3 <- m[1:9,] #Indexed matrix to exclude the last row
```

## 6) BASIC DATA VISUALIZATION AND STATISTICAL ANALYSIS
### Load Zooplankton Data Set

In the R code chunk below, do the following:
1) Load the zooplankton data set from the **3.RStudio** data folder.
2) Display the structure of this data set.

```{r}
meso <- read.table("data/zoop_nuts.txt", sep = "\t", header = TRUE)
str(meso) #Shows structure of data frame, not the same as matrix or vector as matrix and vectors are only comprised of a single data type (i.e. num or int, not both)

```

### Correlation

In the R-code chunk below, do the following:
1) Create a matrix with the numerical data in the `meso` dataframe.
2) Visualize the pairwise **bi-plots** of the six numerical variables.
3) Conduct a simple **Pearson's correlation** analysis.

```{r}
meso.num <- meso [,3:8]#Creates indexed matrix of dataframe. Excludes categorical data
pairs(meso.num)#Gives bi-plots of meso.num matrix
cor1 <- cor(meso.num)
cor1 #Conducts Pearson's correlation. 1-.5 (strong,positive), .5-.3 (moderate,positive), .3-0 (weak,positive), 0 (no correlation), 0-(-.3) (weak,negative), -.3-(-.5) (moderate, negative), -.5-(-1) (strong, negative) 
```


***Question 3***: Describe some of the general features based on the visualization and correlation analysis above?

> Answer 3: General features would include strong and moderate correlations between the variables being studied, in addition to some weak, negative correlations. The data is presented in such a way that one can check a correlation between each of the two variables being looked at. No p-values are provided.


In the R code chunk below, do the following:
1) Redo the correlation analysis using the `corr.test()` function in the `psych` package with the following options: method = "pearson", adjust = "BH".
2) Now, redo this correlation analysis using a non-parametric method.
3) Use the print command from the handout to see the results of each correlation analysis.

```{r}
install.packages("psych", repos="http://cran.rstudio.com/")
require("psych")
cor2 <- corr.test(meso.num, method = "pearson", adjust = "BH")
print(cor2, digits = 3)#provides P-values for Pearson correlation
cor3 <- corr.test(meso.num, method = "kendal", adjust = "BH")
cor3
print(cor3, digits = 3)

```

***Question 4***: 
Describe what you learned from `corr.test`. 
Specifically, are the results sensitive to whether you use parametric (i.e., Pearson's) or non-parametric methods?
When should one use non-parametric methods instead of parametric methods?
With the Pearson's method, is there evidence for false discovery rate due to multiple comparisons? 
Why is false discovery rate important?

> Answer 4: The corr.test allows us to see if there is a strong or weak, positive or negative correlation between two variables. The results are sensitive to whether one uses parametric or non-parametric methods. One should use non-parametric methods when the data is not normality distributed, if there is unequal varience, if the sample is too small, or if the data is ordinal or nominal. There is evidence for false discovery rate due to multiple comparisons with the Pearson's method, the adjustment is the Benjamin & Hochberg-corrected P-values. False discovery rate is important because as the number of tests performed increases, the probability of getting a significant P-value just by chance increases (Type-1 error).  

### Linear Regression

In the R code chunk below, do the following:
1) Conduct a linear regression analysis to test the relationship between total nitrogen (TN) and zooplankton biomass (ZP).
2) Examine the output of the regression analysis.
3) Produce a plot of this regression analysis including the following: categorically labeled points, the predicted regression line with 95% confidence intervals, and the appropriate axis labels.

```{r}
fitreg <- lm(ZP ~ TN, data = meso)
summary(fitreg) #Gives a sign. P-value, indicating that TN is a good predictor of ZP.
plot(meso$TN, meso$ZP, ylim = c(0,10), xlim = c(500, 5000), xlab = expression(paste("Total Nitrogen (", mu, "g/L)")), ylab = "Zooplankton Biomass (mg/L)", las = 1) #makes plot
text(meso$TN, meso$ZP, meso$NUTS, pos = 3, cex = 0.8)#adds letters to points on plot
newTN <- seq(min(meso$TN), max(meso$TN), 10)#adds regression line
regline <- predict(fitreg, newdata = data.frame(TN = newTN))
lines(newTN, regline)
conf95 <- predict(fitreg, newdata = data.frame(TN = newTN), interval = c("confidence"), level = 0.95, type = "response")
matlines(newTN, conf95[, c("lwr", "upr")], type = "l", lty = 2, lwd = 1, col = "black")#adds 95% confidence intervals

```

***Question 5***: Interpret the results from the regression model

> Answer 5:The regression model shows us that Total Nitrogen is indeed a good predictor of zooplankton biomass. We see that as Total Nitrogen increases, so does the zooplankton biomass. The categorically labeled points are epsecially helpful as we can visually distinguish how high Total Nitrogen concentrations differ from low Total Nitrogen concentrations in terms of how they affect zooplanktion biomass.


```{r}

```

### Analysis of Variance (ANOVA)

Using the R code chunk below, do the following:
1) Order the nutrient treatments from low to high (see handout).
2) Produce a barplot to visualize zooplankton biomass in each nutrient treatment.
3) Include error bars (+/- 1 sem) on your plot and label the axes appropriately.
4) Use a one-way analysis of variance (ANOVA) to test the null hypothesis that zooplankton biomass is affected by the nutrient treatment.


```{r}
NUTS <- factor(meso$NUTS, levels = c('L', 'M', 'H'))
zp.means <- tapply(meso$ZP, NUTS, mean)
sem <- function(x){sd(na.omit(x))/sqrt(length(na.omit(x)))}
zp.sem <- tapply(meso$ZP, NUTS, sem)#gives the mean of ZP based on info from other columns (nutrition treatment)

bp <- barplot(zp.means, ylim =c(0, round(max(meso$ZP), digits = 0)), pch = 15, cex = 1.25, las = 1, cex.lab = 1.4, cex.axis = 1.25, xlab = "nutrient supply", ylab = "zooplankton biomass (mg/L)", names.arg = c("low", "medium", "high"))#Creates barplot

arrows(x0 = bp, y0 = zp.means, y1 = zp.means - zp.sem, angle = 90, length = 0.1, lwd = 1)
arrows(x0 = bp, y0 = zp.means, y1 = zp.means + zp.sem, angle = 90, length = 0.1, lwd = 1)#makes error bars.

fitanova <- aov(ZP ~ NUTS, data = meso)#runs anova
summary(fitanova)#Significant p-value. There is a difference in zooplankton biomass between the three different nutrition groups. This however does not say where the difference lies.

TukeyHSD(fitanova)#The differences in zooplankton biomasses are significant between the low and high nutrition groups, and the medium and high nutrition groups. There is no significant difference in zooplankton biomass between medium and high nutrition groups.

```

## SYNTHESIS: SITE-BY-SPECIES MATRIX

In the R code chunk below, load the zoops.txt data set in your **3.RStudio** data folder.
Create a site-by-species matrix (or dataframe) that does *not* include TANK or NUTS.
The remaining columns of data refer to the biomass (µg/L) of different zooplankton taxa: 
  
  + CAL = calanoid copepods
  
  + DIAP = *Diaphanasoma* sp. 
  
  + CYL = cyclopoid copepods
  
  + BOSM = *Bosmina* sp.
  
  + SIMO = *Simocephallus* sp.
  
  + CERI = *Ceriodaphnia* sp.
  
  + NAUP = naupuli (immature copepod)
  
  + DLUM = *Daphnia lumholtzi*
  
  + CHYD = *Chydorus* sp. 

***Question 6***: With the visualization and statistical tools that we learned about in the **3. RStudio** handout, use the site-by-species matrix to assess whether and how different zooplankton taxa were responsible for the total biomass (ZP) response to nutrient enrichment. 
Describe what you learned below in the "Answer" section and include appropriate code in the R chunk.

```{r}
zooptaxa <- read.table("data/zoops.txt", sep = "\t", header = TRUE)#Imports data
zooptaxa#Shows data
str(zooptaxa)#shows what is integer, character, and number in data
zooptaxa.num <- zooptaxa[,3:11]#Indexes dataframe so that only numerical data is present. Nutrition (which is a character) and Tank (which is an integer) are excluded. 
NUTS <- factor(zooptaxa$NUTS, levels = c('L', 'M', 'H')) 
#CAL
CAL.means <- tapply(zooptaxa$CAL, NUTS, mean)
CAL.sem <- tapply(zooptaxa$CAL, NUTS, sem)

bpCAL <- barplot(CAL.means, ylim =c(0, round(max(zooptaxa$CAL), digits = 0)), pch = 15, cex = 1.25, las = 1, cex.lab = 1.4, cex.axis = 1.25, xlab = "nutrient supply", ylab = "zooplankton biomass (mg/L)", names.arg = c("low", "medium", "high"))#Creates barplot
arrows(x0 = bp, y0 = CAL.means, y1 = CAL.means - CAL.sem, angle = 90, length = 0.1, lwd = 1)
arrows(x0 = bp, y0 = CAL.means, y1 = CAL.means + CAL.sem, angle = 90, length = 0.1, lwd = 1)#More in Medium and Low compared to High. 




#DIAP
DIAP.means <- tapply(zooptaxa$DIAP, NUTS, mean)
DIAP.sem <- tapply(zooptaxa$DIAP, NUTS, sem)

bpDIAP <- barplot(DIAP.means, ylim =c(0, round(max(zooptaxa$DIAP), digits = 0)), pch = 15, cex = 1.25, las = 1, cex.lab = 1.4, cex.axis = 1.25, xlab = "nutrient supply", ylab = "zooplankton biomass (mg/L)", names.arg = c("low", "medium", "high"))#Creates barplot
arrows(x0 = bp, y0 = DIAP.means, y1 = DIAP.means - DIAP.sem, angle = 90, length = 0.1, lwd = 1)
arrows(x0 = bp, y0 = DIAP.means, y1 = DIAP.means + DIAP.sem, angle = 90, length = 0.1, lwd = 1)#More in Low and Medium compared to High.



#CYCL
CYCL.means <- tapply(zooptaxa$CYCL, NUTS, mean)
CYCL.sem <- tapply(zooptaxa$CYCL, NUTS, sem)

bpCYCL <- barplot(CYCL.means, ylim =c(0, round(max(zooptaxa$CYCL), digits = 0)), pch = 15, cex = 1.25, las = 1, cex.lab = 1.4, cex.axis = 1.25, xlab = "nutrient supply", ylab = "zooplankton biomass (mg/L)", names.arg = c("low", "medium", "high"))#Creates barplot
arrows(x0 = bp, y0 = CYCL.means, y1 = CYCL.means - CYCL.sem, angle = 90, length = 0.1, lwd = 1)
arrows(x0 = bp, y0 = CYCL.means, y1 = CYCL.means + CYCL.sem, angle = 90, length = 0.1, lwd = 1)#More in Medium



#BOSM
BOSM.means <- tapply(zooptaxa$BOSM, NUTS, mean)
BOSM.sem <- tapply(zooptaxa$BOSM, NUTS, sem)

bpBOSM <- barplot(BOSM.means, ylim =c(0, round(max(zooptaxa$BOSM), digits = 0)), pch = 15, cex = 1.25, las = 1, cex.lab = 1.4, cex.axis = 1.25, xlab = "nutrient supply", ylab = "zooplankton biomass (mg/L)", names.arg = c("low", "medium", "high"))#Creates barplot
arrows(x0 = bp, y0 = BOSM.means, y1 = BOSM.means - BOSM.sem, angle = 90, length = 0.1, lwd = 1)
arrows(x0 = bp, y0 = BOSM.means, y1 = BOSM.means + BOSM.sem, angle = 90, length = 0.1, lwd = 1)#More in Medium



#SIMO
SIMO.means <- tapply(zooptaxa$SIMO, NUTS, mean)
SIMO.sem <- tapply(zooptaxa$SIMO, NUTS, sem)

bpSIMO <- barplot(SIMO.means, ylim =c(0, round(max(zooptaxa$SIMO), digits = 0)), pch = 15, cex = 1.25, las = 1, cex.lab = 1.2, cex.axis = .9, xlab = "nutrient supply", ylab = "zooplankton biomass (mg/L)", names.arg = c("low", "medium", "high"))#Creates barplot
arrows(x0 = bp, y0 = SIMO.means, y1 = SIMO.means - SIMO.sem, angle = 90, length = 0.1, lwd = 1)
arrows(x0 = bp, y0 = SIMO.means, y1 = SIMO.means + SIMO.sem, angle = 90, length = 0.1, lwd = 1)#More in High



#CERI
CERI.means <- tapply(zooptaxa$CERI, NUTS, mean)
CERI.sem <- tapply(zooptaxa$CERI, NUTS, sem)

bpCERI <- barplot(CERI.means, ylim =c(0, round(max(zooptaxa$CERI), digits = 0)), pch = 15, cex = 1.25, las = 1, cex.lab = 1.4, cex.axis = 1.25, xlab = "nutrient supply", ylab = "zooplankton biomass (mg/L)", names.arg = c("low", "medium", "high"))#Creates barplot
arrows(x0 = bp, y0 = CERI.means, y1 = CERI.means - CERI.sem, angle = 90, length = 0.1, lwd = 1)
arrows(x0 = bp, y0 = CERI.means, y1 = CERI.means + CERI.sem, angle = 90, length = 0.1, lwd = 1)#more in Low and High



#NAUP
NAUP.means <- tapply(zooptaxa$NAUP, NUTS, mean)
NAUP.sem <- tapply(zooptaxa$NAUP, NUTS, sem)

bpNAUP <- barplot(NAUP.means, ylim =c(0, round(max(zooptaxa$NAUP), digits = 0)), pch = 15, cex = 1.25, las = 1, cex.lab = 1.4, cex.axis = 1.25, xlab = "nutrient supply", ylab = "zooplankton biomass (mg/L)", names.arg = c("low", "medium", "high"))#Creates barplot
arrows(x0 = bp, y0 = NAUP.means, y1 = NAUP.means - NAUP.sem, angle = 90, length = 0.1, lwd = 1)
arrows(x0 = bp, y0 = NAUP.means, y1 = NAUP.means + NAUP.sem, angle = 90, length = 0.1, lwd = 1)#More in Low



#DLUM
DLUM.means <- tapply(zooptaxa$DLUM, NUTS, mean)
DLUM.sem <- tapply(zooptaxa$DLUM, NUTS, sem)

bpDLUM <- barplot(DLUM.means, ylim =c(0, round(max(zooptaxa$DLUM), digits = 0)), pch = 15, cex = 1.25, las = 1, cex.lab = 1.4, cex.axis = 1.25, xlab = "nutrient supply", ylab = "zooplankton biomass (mg/L)", names.arg = c("low", "medium", "high"))#Creates barplot
arrows(x0 = bp, y0 = DLUM.means, y1 = DLUM.means - DLUM.sem, angle = 90, length = 0.1, lwd = 1)
arrows(x0 = bp, y0 = DLUM.means, y1 = DLUM.means + DLUM.sem, angle = 90, length = 0.1, lwd = 1)#Only in Low

#CHYD
CHYD.means <- tapply(zooptaxa$CHYD, NUTS, mean)
CHYD.sem <- tapply(zooptaxa$CHYD, NUTS, sem)

bpCHYD <- barplot(CHYD.means, ylim =c(0, round(max(zooptaxa$CHYD), digits = 0)), pch = 15, cex = 1.25, las = 1, cex.lab = 1.2, cex.axis = .9, xlab = "nutrient supply", ylab = "zooplankton biomass (mg/L)", names.arg = c("low", "medium", "high"))#Creates barplot
arrows(x0 = bp, y0 = CHYD.means, y1 = CHYD.means - CHYD.sem, angle = 90, length = 0.1, lwd = 1)
arrows(x0 = bp, y0 = CHYD.means, y1 = CHYD.means + CHYD.sem, angle = 90, length = 0.1, lwd = 1)#More in High

```

## SUBMITTING YOUR WORKSHEET
Use Knitr to create a PDF of your completed **3.RStudio_Worksheet.Rmd** document, push the repo to GitHub, and create a pull request.
Please make sure your updated repo include both the PDF and RMarkdown files.

This assignment is due on **Wednesday, January 18^th^, 2021 at 12:00 PM (noon)**.

 Answer to Question 6: By looking at barplots of different species biomasses at different nutrition levels I can see that different taxa do, visually speaking, differ. I was running anovas on taxa by nutrition level then realized that some of the taxa data might not meet the assumptions of an anova. By looking at the barplots I can say that different taxa differ in how much biomass they contribute to the different nutrition levels. For example, CHYD seem to contribute more biomass at High levels of nutrition compared to DLUM which only contribute biomass at Low levels of nutrition.
